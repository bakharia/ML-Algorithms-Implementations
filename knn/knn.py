# -*- coding: utf-8 -*-
"""KNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wQlRHKwIvW1br6UfzoU-anm_dcZVXCR-
"""

from collections import Counter
from sklearn.utils import shuffle
from sklearn.preprocessing import StandardScaler

import numpy as np
import matplotlib.pyplot as plt

def euclidean_norm(x1, x2):
    return np.sqrt(np.sum((x1 - x2) ** 2))

class knn:
    def __init__(self, k=3):
        self.k = k

    def fit(self, X, y):
        self.X_train = X
        self.y_train = y

    def predict(self, X):
        y_pred = [self._predict(x) for x in X]
        return np.array(y_pred)

    def _predict(self, x):
        # Calculate norm
        norm = [euclidean_norm(x, x_train) for x_train in self.X_train]
        # Indices of the first k neighbors
        k_indices = np.argsort(norm)[: self.k]
        # Labels of the k nearest neighbors
        k_neighbor_labels = [self.y_train[i] for i in k_indices]
        # return the mode of the class labels
        mode = Counter(k_neighbor_labels).most_common(1)
        return mode[0][0]

def accuracy(y_actual, y_pred):
        accuracy = np.sum(y_actual == y_pred) / len(y_actual)
        return accuracy

if __name__ == "__main__":
    mean_test_scores = []
    sd_test_scores = []
    mean_train_scores = []
    sd_train_scores = []

    # Imports
    from matplotlib.colors import ListedColormap
    from sklearn import datasets
    from sklearn.model_selection import train_test_split

    iris = datasets.load_iris()

    X, y = iris.data, iris.target

    k = [i for i in range(1,52,2)]

    for k in range(1, 52, 2):
      test_scores = []
      train_scores = []

      for i in range(20):
        classification = knn(k=k)
        X, y = shuffle(X, y)
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
        
        sc = StandardScaler()
        X_train = sc.fit_transform(X_train)
        X_test = sc.transform(X_test)

        classification.fit(X_train, y_train)

        predictions_train = classification.predict(X_train)
        train_scores.append(accuracy(y_train, predictions_train))

        predictions_test = classification.predict(X_test)
        test_scores.append(accuracy(y_test, predictions_test))

      mean_test_scores.append(sum(test_scores) / len(test_scores))
      mean_train_scores.append(sum(train_scores) / len(train_scores))
      sd_test_scores.append(np.std(test_scores))
      sd_train_scores.append(np.std(train_scores))

# plt.errorbar([i for i in range(1,52,2)], mean_train_scores, yerr= sd_train_scores, marker = 'o')
# plt.xlabel('K value')
# plt.ylabel('Accuracy scores')
# plt.title('Figure 1.1: Accuracy vs. k for Training Set')
# plt.show()

# """1.1. Figure 1.1 above shows the average accuracy of models trained over the training set, for all k in (1, 3, . . . , 51). For each point in the graph, the corresponding standard deviation is shown by the error bars to each point."""

# plt.errorbar([i for i in range(1,52,2)], mean_test_scores, yerr= sd_test_scores, marker = 'o')
# plt.xlabel('K value')
# plt.ylabel('Accuracy scores')
# plt.title('Figure 1.2:  Accuracy vs. k for Testing Set')
# plt.show()

"""1.2. Figure 1.2 above shows the average accuracy of models trained over the testing set, for all k in (1, 3, . . . , 51). For each point in the graph, the corresponding standard deviation is shown by the error bars to each point.

1.3 In case of the first graph, the accuracy for k = 1 results in an overly flexible fit to the data. By increaing k slightly, the accuracy results become more realistic. However, increasing k beyond 10 turns out to provide no further improvements.

In case of the second graph, the accuracy somewhat increases for k <= 20, and then the accuracy falls for higher values of k. Since the size of the test data is smaller, the KNN algorithm oes not learn anything from the test dataand thus 
requires larger values of k to improve the accuracy. However, after a large enough k, the accuracy starts decreasing because of underfitting. For higher values of k, the error bars are also increasing in height, thereby suggesting underfitting.

In case of both the graphs, the accuracy falls for higher values of k. This is due to underfitting. 

Additionally, the standard deviation of accuracy scores for each value of k also increases for higher values of k due to the underfitting. This is evident of from larger height of the error bars for higher values of k.

1.4. For 5 < k < 10, the knn is overfitting and for k > 20, the knn is underfitting. This is evident from the secular decline in the accuracy levels for k > 20 and the larger heights of the error bars.

1.5. A small value of K means that noise will have a higher influence on the result Larger the value of K, higher is the accuracy. If K is too large, the the error will increase due to underfitting. Moreover, larger k will also increase the computational expense of the algorithm. I will choose k = square root of the number of samples in the training dataset, i.e., k = 11. Also, for k > 11, the accuracy of KNN algorithm does not increase. So, it's safe to choose k = 11.
"""