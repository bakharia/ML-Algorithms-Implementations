# -*- coding: utf-8 -*-
"""Decision_Tree.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xvxcjVA7H8b7nzdQTfEgNe2S__kxsWM5

2. Evaluating the Decision Tree Algorithm
"""

# Commented out IPython magic to ensure Python compatibility.
# Importing the required packages

from collections import Counter
from math import log2
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import warnings
# %matplotlib inline

class Node:
   def __init__(self, feature=None, threshold=None, data_left=None, data_right=None, gain=None, value=None):
        self.feature = feature
        self.threshold = threshold
        self.data_left = data_left
        self.data_right = data_right
        self.gain = gain
        self.value = value

class DecisionTree:
    '''
    Class which implements a decision tree classifier algorithm.
    '''
    def __init__(self, min_samples_split=2, max_depth=5):
        self.min_samples_split = min_samples_split
        self.max_depth = max_depth
        self.root = None
        
    @staticmethod
    def _entropy(s):
        '''
        Helper function, calculates entropy from an array of integer values.
        
        :param s: list
        :return: float, entropy value
        '''
        # Convert to integers to avoid runtime errors
        counts = np.bincount(np.array(s, dtype=np.int64))
        # Probabilities of each class label
        percentages = counts / len(s)

        # Caclulate entropy
        entropy = 0
        for pct in percentages:
            if pct > 0:
                entropy += pct * np.log2(pct)
        return -entropy
    
    def _information_gain(self, parent, left_child, right_child):
        '''
        Helper function, calculates information gain from a parent and two child nodes.
        
        :param parent: list, the parent node
        :param left_child: list, left child of a parent
        :param right_child: list, right child of a parent
        :return: float, information gain
        '''
        num_left = len(left_child) / len(parent)
        num_right = len(right_child) / len(parent)
        
        # One-liner which implements the previously discussed formula
        return self._entropy(parent) - (num_left * self._entropy(left_child) + num_right * self._entropy(right_child))
    
    def _best_split(self, X, y):
        '''
        Helper function, calculates the best split for given features and target
        
        :param X: np.array, features
        :param y: np.array or list, target
        :return: dict
        '''
        best_split = {}
        best_info_gain = -1
        n_rows, n_cols = X.shape
        
        # For every dataset feature
        for f_idx in range(n_cols):
            X_curr = X[:, f_idx]
            # For every unique value of that feature
            for threshold in np.unique(X_curr):
                # Construct a dataset and split it to the left and right parts
                # Left part includes records lower or equal to the threshold
                # Right part includes records higher than the threshold
                df = np.concatenate((X, y.reshape(1, -1).T), axis=1)
                df_left = np.array([row for row in df if row[f_idx] <= threshold])
                df_right = np.array([row for row in df if row[f_idx] > threshold])

                # Do the calculation only if there's data in both subsets
                if len(df_left) > 0 and len(df_right) > 0:
                    # Obtain the value of the target variable for subsets
                    y = df[:, -1]
                    y_left = df_left[:, -1]
                    y_right = df_right[:, -1]

                    # Caclulate the information gain and save the split parameters
                    # if the current split if better then the previous best
                    gain = self._information_gain(y, y_left, y_right)
                    if gain > best_info_gain:
                        best_split = {
                            'feature_index': f_idx,
                            'threshold': threshold,
                            'df_left': df_left,
                            'df_right': df_right,
                            'gain': gain
                        }
                        best_info_gain = gain
        return best_split
    
    def _build(self, X, y, depth=0):
        '''
        Helper recursive function, used to build a decision tree from the input data.
        
        :param X: np.array, features
        :param y: np.array or list, target
        :param depth: current depth of a tree, used as a stopping criteria
        :return: Node
        '''
        n_rows, n_cols = X.shape
        
        # Check to see if a node should be leaf node
        if n_rows >= self.min_samples_split and depth <= self.max_depth:
            # Get the best split
            best = self._best_split(X, y)
            # If the split isn't pure
            if best['gain'] > 0:
                # Build a tree on the left
                left = self._build(
                    X=best['df_left'][:, :-1], 
                    y=best['df_left'][:, -1], 
                    depth=depth + 1
                )
                right = self._build(
                    X=best['df_right'][:, :-1], 
                    y=best['df_right'][:, -1], 
                    depth=depth + 1
                )
                return Node(
                    feature=best['feature_index'], 
                    threshold=best['threshold'], 
                    data_left=left, 
                    data_right=right, 
                    gain=best['gain']
                )
        # Leaf node - value is the most common target value 
        return Node(
            value= Counter(y).most_common(1)[0][0]
        )
    
    def fit(self, X, y):
        '''
        Function used to train a decision tree classifier model.
        
        :param X: np.array, features
        :param y: np.array or list, target
        :return: None
        '''
        # Call a recursive function to build the tree
        self.root = self._build(X, y)
        
    def _predict(self, x, tree):
        '''
        Helper recursive function, used to predict a single instance (tree traversal).
        
        :param x: single observation
        :param tree: built tree
        :return: float, predicted class
        '''
        # Leaf node
        if tree.value != None:
            return tree.value
        feature_value = x[tree.feature]
        
        # Go to the left
        if feature_value <= tree.threshold:
            return self._predict(x=x, tree=tree.data_left)
        
        # Go to the right
        if feature_value > tree.threshold:
            return self._predict(x=x, tree=tree.data_right)
        
    def predict(self, X):
        '''
        Function used to classify new instances.
        
        :param X: np.array, features
        :return: np.array, predicted classes
        '''
        # Call the _predict() function for every observation
        return [self._predict(x, self.root) for x in X]
if __name__ == '__main__':
    df = pd.read_csv('house_votes_84.csv')

    X = np.array(df.iloc[:, :-1], dtype = np.int64)
    y = np.array(df.iloc[:, -1], dtype = np.int64)

    test_scores = []
    train_scores = []

    for i in range(100):

        X, y = shuffle(X, y)
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)
        
        model = DecisionTree()
        model.fit(X_train, y_train)

        test_preds = model.predict(X_test)
        test_scores.append(accuracy_score(y_test, test_preds))

        train_preds = model.predict(X_train)
        train_scores.append(accuracy_score(y_train, train_preds))

    plt.hist(train_scores, density=True, bins = 35, edgecolor='black')
    plt.ylabel('Accuracy frequency on the Training data')
    plt.xlabel('Accuracy')
    plt.title('Figure 2.1: Histogram of Accuracy scores for the Training Set')
    plt.show()

    mean_train_scores = (sum(train_scores) / len(train_scores))
    sd_train_scores = (np.std(train_scores))
    #print(mean_train_scores, sd_train_scores)

    """2.1. Figure 2.1 above shows the accuracy distribution when the algorithm was evaluated over training data. The mean accuracy is 0.9930 and the standard deviation of accuracy is 0.003."""

    plt.hist(test_scores, density=True, bins = 35, edgecolor='black')
    plt.ylabel('Accuracy frequency on the Test data')
    plt.xlabel('Accuracy')
    plt.title('Figure 2.2: Histogram of Accuracy scores for the Test Set')
    plt.show()

    mean_test_scores = (sum(test_scores) / len(test_scores))
    sd_test_scores = (np.std(test_scores))
    print(mean_test_scores, sd_test_scores)

    """2.2. Figure 2.2 shows the accuracy distribution when the algorithm was evaluated over testing data. The mean accuracy is 0.943 and the standard deviation of accuracy is 0.021.

    2.3. The variance in the accuracy scores for the test data is greater compared to the variance in the accuracy score for the trainin data. Additionally the average accuracy of the training data is greater than the average accuracy of the test data. This may be the case due to the overfitting of the training data. Overfitting of the training data might have made the model attached to training data and increases the level of complexity. Instead of being generic model it become more centric to specific conditions as the number of levels increases.

    2.4. In our dataset, the decision tree model seems to suffer from overfitting. Decision Tree generally leads to overfitting of the data which consequently leads to wrong predictions. While fitting the data, it keeps generating new nodes, which ultimately makes the tree too complex to interpret. In this way, it loses its generalization capabilities. It performs very well on the trained data but starts making a lot of mistakes on the unseen data.

    2.5 Although decision trees are robust in terms of the data types they can handle, the algorithm itself is not very robust. If we split the training data into two parts at random, and fit a decision tree to both halves, the results that we get could be quite different. A small change in the data can dramatically change the final estimated tree.
    """